{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = np.loadtxt('data.csv', delimiter = ',')\n",
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((100,), (100,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = d[:, 0]\n",
    "y = d[:, 1]\n",
    "x.shape , y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(x,y,n,m,c):\n",
    "    return 1/n * ((y - m*x - c) ** 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, alpha, iterations):\n",
    "    n = x.shape[0]\n",
    "    m,c = 0,0\n",
    "    for _iterations in range(iterations):\n",
    "        m_slope = ((-2/n) * (y - m * x - c) * x).sum()\n",
    "        c_slope = ((-2/n) * (y - m * x - c)).sum()\n",
    "        m -= (alpha * m_slope)\n",
    "        c -= (alpha * c_slope)\n",
    "        print(score(x,y,n,m,c), m,c)\n",
    "    return m,c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1484.5865574086483 0.7370702973591055 0.014547010110737293\n",
      "457.8542575737669 1.106795454351516 0.021873962959596406\n",
      "199.50998572553866 1.2922546649131117 0.02557922432129313\n",
      "134.50591058200536 1.385283255651245 0.027467789559144345\n",
      "118.14969342239947 1.4319472323843205 0.028445071981738953\n",
      "114.03414906038152 1.4553540088980408 0.028965240766478606\n",
      "112.99857731713662 1.4670946177201354 0.029256114126046687\n",
      "112.73798187568465 1.4729832982243762 0.029431969163807113\n",
      "112.67238435909101 1.4759365618962286 0.029550129024383056\n",
      "112.65585181499748 1.47741737554838 0.029639347874732373\n",
      "112.65166489759584 1.4781595857319894 0.029714049245227026\n",
      "112.65058436150107 1.4785313011122556 0.0297814681995265\n",
      "112.650285447015 1.4787171706313593 0.0298452339563324\n",
      "112.65018320293971 1.47880981702566 0.029907166987310222\n",
      "112.65013044507198 1.4788557012777628 0.029968180468920375\n",
      "112.65009013922882 1.4788781289278567 0.030028732464457777\n",
      "112.65005296694633 1.4788887903917065 0.030089052745485775\n",
      "112.65001658353182 1.4788935497608395 0.03014925656894004\n",
      "112.64998039901867 1.4788953485533443 0.030209401749465785\n",
      "112.64994426496071 1.4788956622797287 0.03026951728777589\n",
      "112.6499081440062 1.4788952310786532 0.030329617731073642\n",
      "112.64987202675677 1.4788944262150014 0.030389710376460634\n",
      "112.64983591084761 1.4788934339209232 0.030449798884276447\n",
      "112.64979979568366 1.4788923476133156 0.03050988509060516\n",
      "112.64976368111526 1.4788912141515247 0.03056996991645636\n",
      "112.64972756710463 1.4788900570409158 0.030630053823824274\n",
      "112.64969145364239 1.4788888880721398 0.03069013704445397\n",
      "112.64965534072611 1.478887713159568 0.03075021969459404\n",
      "112.64961922835515 1.4788865352699392 0.03081030183255826\n",
      "112.64958311652936 1.4788853558914152 0.030870383487599417\n",
      "112.64954700524873 1.4788841757704807 0.030930464674392862\n",
      "112.64951089451318 1.4788829952815838 0.030990545400301685\n",
      "112.64947478432279 1.4788818146125533 0.031050625669021024\n",
      "112.6494386746775 1.478880633857607 0.03111070548240613\n",
      "112.64940256557725 1.478879453064006 0.03117078484138933\n",
      "112.64936645702214 1.478878272255457 0.031230863746439994\n",
      "112.64933034901203 1.478877091443852 0.031290942197795275\n",
      "112.64929424154707 1.4788759106351557 0.03135102019557584\n",
      "112.6492581346271 1.4788747298323603 0.03141109773984392\n",
      "112.64922202825224 1.4788735490369667 0.031471174830632435\n",
      "112.64918592242239 1.4788723682497276 0.03153125146795961\n",
      "112.64914981713753 1.4788711874710208 0.03159132765183629\n",
      "112.64911371239778 1.4788700067010354 0.03165140338226961\n",
      "112.64907760820297 1.4788688259398666 0.03171147865926488\n",
      "112.64904150455322 1.478867645187562 0.031771553482826446\n",
      "112.64900540144845 1.4788664644441452 0.0318316278529582\n",
      "112.64896929888866 1.4788652837096283 0.0318917017696638\n",
      "112.64893319687388 1.4788641029840173 0.03195177523294679\n",
      "112.64889709540405 1.478862922267315 0.03201184824281065\n",
      "112.64886099447922 1.478861741559523 0.032071920799258836\n",
      "112.6488248940993 1.478860560860642 0.03213199290229478\n",
      "112.64878879426439 1.478859380170672 0.03219206455192191\n",
      "112.64875269497436 1.4788581994896135 0.03225213574814366\n",
      "112.64871659622932 1.4788570188174663 0.032312206490963453\n",
      "112.64868049802918 1.4788558381542305 0.03237227678038471\n",
      "112.64864440037394 1.478854657499906 0.03243234661641085\n",
      "112.64860830326363 1.4788534768544928 0.032492415999045295\n",
      "112.6485722066982 1.4788522962179906 0.03255248492829147\n",
      "112.64853611067774 1.4788511155903998 0.032612553404152804\n",
      "112.64850001520212 1.47884993497172 0.03267262142663271\n",
      "112.64846392027134 1.478848754361951 0.03273268899573461\n",
      "112.64842782588546 1.4788475737610933 0.03279275611146193\n",
      "112.64839173204442 1.4788463931691462 0.03285282277381809\n",
      "112.64835563874826 1.47884521258611 0.03291288898280651\n",
      "112.64831954599691 1.4788440320119847 0.03297295473843062\n",
      "112.64828345379041 1.47884285144677 0.03303302004069383\n",
      "112.64824736212877 1.4788416708904657 0.033093084889599576\n",
      "112.64821127101193 1.478840490343072 0.03315314928515127\n",
      "112.64817518043985 1.4788393098045889 0.03321321322735234\n",
      "112.64813909041263 1.4788381292750161 0.033273276716206196\n",
      "112.64810300093019 1.4788369487543536 0.03333333975171627\n",
      "112.6480669119926 1.4788357682426014 0.03339340233388598\n",
      "112.64803082359965 1.4788345877397595 0.03345346446271875\n",
      "112.64799473575157 1.4788334072458276 0.033513526138217994\n",
      "112.64795864844822 1.4788322267608058 0.033573587360387146\n",
      "112.64792256168965 1.478831046284694 0.03363364812922962\n",
      "112.64788647547579 1.4788298658174923 0.03369370844474884\n",
      "112.64785038980666 1.4788286853592003 0.03375376830694822\n",
      "112.64781430468231 1.478827504909818 0.03381382771583119\n",
      "112.64777822010265 1.4788263244693456 0.03387388667140117\n",
      "112.64774213606773 1.4788251440377829 0.033933945173661585\n",
      "112.64770605257743 1.4788239636151297 0.03399400322261585\n",
      "112.6476699696319 1.478822783201386 0.03405406081826739\n",
      "112.64763388723104 1.4788216027965517 0.034114117960619625\n",
      "112.64759780537486 1.478820422400627 0.034174174649675974\n",
      "112.64756172406335 1.4788192420136115 0.034234230885439865\n",
      "112.64752564329652 1.478818061635505 0.03429428666791472\n",
      "112.64748956307433 1.478816881266308 0.03435434199710395\n",
      "112.64745348339677 1.47881570090602 0.03441439687301098\n",
      "112.64741740426388 1.4788145205546412 0.03447445129563924\n",
      "112.6473813256756 1.4788133402121713 0.03453450526499214\n",
      "112.64734524763193 1.4788121598786104 0.034594558781073106\n",
      "112.6473091701329 1.4788109795539583 0.03465461184388556\n",
      "112.64727309317846 1.478809799238215 0.03471466445343292\n",
      "112.64723701676859 1.4788086189313803 0.03477471660971861\n",
      "112.64720094090333 1.4788074386334544 0.03483476831274605\n",
      "112.64716486558272 1.478806258344437 0.034894819562518664\n",
      "112.6471287908066 1.4788050780643283 0.03495487035903987\n",
      "112.64709271657509 1.4788038977931277 0.035014920702313095\n",
      "112.64705664288807 1.4788027175308358 0.03507497059234175\n"
     ]
    }
   ],
   "source": [
    "m, c = gradientDescent(x, y, alpha = 0.0001, iterations = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets us try to create Gradient Descent for multiple features\n",
    "def gradientDescentMultipleFeatures(x, y, alpha, iterations):\n",
    "    rows = x.shape[0]\n",
    "    num_features = x.shape(1)\n",
    "    m = [0 for i in range(num_features)]\n",
    "    for _iterations in range(iterations):\n",
    "        for i in range(rows):\n",
    "            mx = 0\n",
    "            for j in range(num_features):\n",
    "                mx += (m[i] * x[i][j])\n",
    "            for j in range(num_features):\n",
    "                m[j] -= alpha * (y[i] - mx) * x[i][j]\n",
    "    return m[:-1], m[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
