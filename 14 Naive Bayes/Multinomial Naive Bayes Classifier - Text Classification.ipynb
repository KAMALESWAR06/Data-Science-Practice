{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# To work with files and folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = './20_newsgroups'\n",
    "# The address of the base folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['talk.politics.mideast',\n",
       " 'rec.autos',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'alt.atheism',\n",
       " 'rec.sport.baseball',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.med',\n",
       " 'talk.politics.misc',\n",
       " 'rec.motorcycles',\n",
       " 'comp.windows.x',\n",
       " 'comp.graphics',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'sci.electronics',\n",
       " 'talk.politics.guns',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'misc.forsale',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folders = [f for f in os.listdir(base) if not f.startswith('.')]\n",
    "folders\n",
    "# These are the different folders in the 20_newsgroups directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_words = ['subject:','from:', 'date:', 'newsgroups:', 'message-id:', 'lines:', 'path:', 'organization:', \n",
    "            'would', 'writes:', 'references:', 'article', 'sender:', 'nntp-posting-host:', 'people', \n",
    "            'university', 'think', 'xref:', 'cantaloupe.srv.cs.cmu.edu', 'could', 'distribution:', 'first', \n",
    "            'anyone','world', 'really', 'since', 'right', 'believe', 'still', \n",
    "            \"max>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'ax>'\",'newsgroups', 'xref', 'path', \n",
    "            'from', 'subject', 'sender', 'organisation', 'apr','gmt', 'last','better','never','every','even','two',\n",
    "            'good','used','first','need','going','must','really','might','well','without','made','give','look',\n",
    "            'try','far','less','seem','new','make','many','way','since','using','take','help','thanks','send',\n",
    "            'free','may','see','much','want','find','would','one','like','get','use','also','could','say','us',\n",
    "            'go','please','said','set','got','sure','come','lot','seems','able','anything','put', '--', '|>', '>>',\n",
    "            '93', 'xref', 'cantaloupe.srv.cs.cmu.edu', '20', '16', '21', '19', '10', '17', '24', 'reply-to:', 'thu',\n",
    "            'nntp-posting-host:', 're:','25''18'\"i'd\"'>i''22''fri,''23''>the','references:','xref:','sender:',\n",
    "            'writes:','1993']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "stop_words += block_words\n",
    "stop_words += list(string.punctuation)\n",
    "# We create a list of stop words and block words, i.e words that we won't use in our vocaubulary, \n",
    "# because they are very common, or do not help us\n",
    "# We will also add punctuations in stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for folder in folders:\n",
    "    files = os.listdir(base +'/'+ folder)\n",
    "    for file in files:\n",
    "        fileobj = open(base + '/' + folder + '/' + file, 'r', errors='ignore')\n",
    "        # We go through all the files\n",
    "        data.append((' '.join([word.lower() for word in fileobj.read().strip().split() if not word.lower() in stop_words and len(word.lower()) > 1]),folder))\n",
    "        # For every file, we remove the stop words, and single words, and extra spaces\n",
    "        # And then join the text back together, And then store it in a n x 2 array, for all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.DataFrame(data, columns = ['text', 'category'])\n",
    "# We convert it inro a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>talk.politics.mideast cantaloupe.srv.cs.cmu.ed...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>talk.politics.mideast:76248 talk.politics.misc...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>talk.politics.mideast:76277 soc.culture.greek:...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>soc.culture.arabic:19746 talk.politics.mideast...</td>\n",
       "      <td>talk.politics.mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19992</td>\n",
       "      <td>talk.religion.misc:83766 talk.politics.misc:17...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19993</td>\n",
       "      <td>talk.religion.misc:82815 talk.religion.newage:...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19994</td>\n",
       "      <td>sci.skeptic:43397 talk.politics.misc:178808 ta...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19995</td>\n",
       "      <td>talk.abortion:120933 talk.religion.misc:83933 ...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19996</td>\n",
       "      <td>talk.abortion:121213 alt.atheism:53802 talk.re...</td>\n",
       "      <td>talk.religion.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19997 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0      talk.politics.mideast cantaloupe.srv.cs.cmu.ed...   \n",
       "1      talk.politics.mideast:76248 talk.politics.misc...   \n",
       "2      talk.politics.mideast:76277 soc.culture.greek:...   \n",
       "3      cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu...   \n",
       "4      soc.culture.arabic:19746 talk.politics.mideast...   \n",
       "...                                                  ...   \n",
       "19992  talk.religion.misc:83766 talk.politics.misc:17...   \n",
       "19993  talk.religion.misc:82815 talk.religion.newage:...   \n",
       "19994  sci.skeptic:43397 talk.politics.misc:178808 ta...   \n",
       "19995  talk.abortion:120933 talk.religion.misc:83933 ...   \n",
       "19996  talk.abortion:121213 alt.atheism:53802 talk.re...   \n",
       "\n",
       "                    category  \n",
       "0      talk.politics.mideast  \n",
       "1      talk.politics.mideast  \n",
       "2      talk.politics.mideast  \n",
       "3      talk.politics.mideast  \n",
       "4      talk.politics.mideast  \n",
       "...                      ...  \n",
       "19992     talk.religion.misc  \n",
       "19993     talk.religion.misc  \n",
       "19994     talk.religion.misc  \n",
       "19995     talk.religion.misc  \n",
       "19996     talk.religion.misc  \n",
       "\n",
       "[19997 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "train_df, test_df = model_selection.train_test_split(data_df, random_state = 0)\n",
    "# Splitting the data into two different dataframes, training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14997, 2) (5000, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape,test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sci.med                     284\n",
       "soc.religion.christian      281\n",
       "sci.crypt                   269\n",
       "rec.sport.hockey            261\n",
       "misc.forsale                259\n",
       "comp.sys.ibm.pc.hardware    256\n",
       "rec.autos                   253\n",
       "talk.politics.guns          253\n",
       "comp.sys.mac.hardware       249\n",
       "talk.politics.misc          248\n",
       "sci.space                   248\n",
       "sci.electronics             246\n",
       "comp.graphics               244\n",
       "alt.atheism                 240\n",
       "comp.os.ms-windows.misc     240\n",
       "talk.religion.misc          236\n",
       "rec.sport.baseball          236\n",
       "talk.politics.mideast       233\n",
       "comp.windows.x              233\n",
       "rec.motorcycles             231\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['category'].value_counts()\n",
    "# We can see that the data is evenly divided, Which will be helpful later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Vocabulary (From training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_basic = {}\n",
    "for row in train_df.values:\n",
    "    for word in row[0].split():\n",
    "        vocab_basic[word] = vocab_basic.get(word, 0) + 1\n",
    "        # We go through our training data, and build a dictionary of all the words and their occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from heapq import nlargest \n",
    "num_features = 2500\n",
    "most_common_words = nlargest(num_features, vocab_basic, key = vocab_basic.get) \n",
    "# Next we use a heap to get the top 2500 most used words,\n",
    "# We will use these words as features for our data\n",
    "vocab = { word:vocab_basic[word] for word in most_common_words} \n",
    "# We build the final vocabulary (as a dictionary named vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 of the most common words: \n",
      "\n",
      "\n",
      "know  \t\t 5749\n",
      "i'm  \t\t 4358\n",
      "time  \t\t 3212\n",
      "it.  \t\t 3126\n",
      "something  \t\t 2362\n",
      "computer  \t\t 2359\n",
      "system  \t\t 2357\n",
      "i've  \t\t 2351\n",
      "15  \t\t 2204\n",
      "god  \t\t 2162\n",
      "news  \t\t 2150\n",
      "state  \t\t 2148\n",
      "can't  \t\t 2137\n",
      "back  \t\t 2053\n",
      "work  \t\t 2024\n",
      "someone  \t\t 1984\n",
      "government  \t\t 1934\n",
      ">in  \t\t 1933\n",
      "problem  \t\t 1915\n",
      "another  \t\t 1886\n",
      "23  \t\t 1873\n",
      "read  \t\t 1861\n",
      "number  \t\t 1860\n",
      "usa  \t\t 1858\n",
      "information  \t\t 1857\n",
      "windows  \t\t 1809\n",
      ">the  \t\t 1806\n",
      "things  \t\t 1771\n",
      "that's  \t\t 1768\n",
      "little  \t\t 1752\n",
      "22  \t\t 1712\n",
      "file  \t\t 1701\n",
      "fri,  \t\t 1694\n",
      "tue,  \t\t 1693\n",
      "point  \t\t 1687\n",
      ">i  \t\t 1677\n",
      "part  \t\t 1665\n",
      "data  \t\t 1627\n",
      "it,  \t\t 1607\n",
      "around  \t\t 1595\n",
      "(usenet  \t\t 1592\n",
      "years  \t\t 1591\n",
      "different  \t\t 1584\n",
      "question  \t\t 1570\n",
      "probably  \t\t 1557\n",
      "long  \t\t 1548\n",
      "available  \t\t 1545\n",
      "software  \t\t 1533\n",
      "tell  \t\t 1506\n",
      "program  \t\t 1505\n"
     ]
    }
   ],
   "source": [
    "print('50 of the most common words: \\n\\n')\n",
    "for i in list(vocab.keys())[:50]:\n",
    "    print(i, ' \\t\\t',vocab[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the data into 2D Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to figure out the columns of the 2D array\n",
    "cols = list(vocab.keys())\n",
    "cols.sort()\n",
    "# print(columns)\n",
    "# Now we have the columns (in sorted order), Let us create the 2D matrix of x\n",
    "# Our output classes will be from the folders array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_data(text,category,features):\n",
    "    # We get the text, the category and the features used\n",
    "    X = []\n",
    "    Y = []\n",
    "    for i in range(len(text)):\n",
    "        current_x = [0 for _i in range(len(features))]\n",
    "        for word in text[i].split():\n",
    "            # We check if the word is a column/feature in our 2D array, If it is then we increment is by 1 at that index\n",
    "            if word in features:\n",
    "                current_x[features.index(word)] += 1 # Go to the column where we have kept that word, and increment it\n",
    "        X.append(current_x) # Add the current row (for current file) to the main 2D matrix\n",
    "        Y.append(category[i]) # Append the class for current file\n",
    "    np_x = np.array(X, dtype = int)\n",
    "    np_y = np.array(Y, dtype = str)\n",
    "    return np_x, np_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = convert_data(train_df['text'].values, train_df['category'].values, cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test,  y_test  = convert_data(test_df['text'].values,  test_df['category'].values,  cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\"a</th>\n",
       "      <th>\"i</th>\n",
       "      <th>\"if</th>\n",
       "      <th>\"it</th>\n",
       "      <th>\"the</th>\n",
       "      <th>\"this</th>\n",
       "      <th>\"we</th>\n",
       "      <th>\"what</th>\n",
       "      <th>\"you</th>\n",
       "      <th>#1</th>\n",
       "      <th>...</th>\n",
       "      <th>yet</th>\n",
       "      <th>yet,</th>\n",
       "      <th>yet.</th>\n",
       "      <th>york</th>\n",
       "      <th>you,</th>\n",
       "      <th>you.</th>\n",
       "      <th>you?</th>\n",
       "      <th>young</th>\n",
       "      <th>yourself.</th>\n",
       "      <th>||</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14992</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14993</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14994</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14996</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14997 rows Ã— 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       \"a  \"i  \"if  \"it  \"the  \"this  \"we  \"what  \"you  #1  ...  yet  yet,  \\\n",
       "0       0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "1       0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "2       0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "3       0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "4       0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "...    ..  ..  ...  ...   ...    ...  ...    ...   ...  ..  ...  ...   ...   \n",
       "14992   0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "14993   0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "14994   0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "14995   0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "14996   0   0    0    0     0      0    0      0     0   0  ...    0     0   \n",
       "\n",
       "       yet.  york  you,  you.  you?  young  yourself.  ||  \n",
       "0         0     0     0     0     0      0          0   0  \n",
       "1         0     0     0     0     0      0          0   0  \n",
       "2         0     0     0     0     0      0          0   0  \n",
       "3         0     0     0     0     0      0          0   0  \n",
       "4         0     0     0     0     0      0          0   0  \n",
       "...     ...   ...   ...   ...   ...    ...        ...  ..  \n",
       "14992     0     0     0     0     0      0          0   0  \n",
       "14993     0     0     0     0     0      0          0   0  \n",
       "14994     0     1     0     0     0      0          0   0  \n",
       "14995     0     0     0     0     0      0          0   0  \n",
       "14996     0     0     0     0     0      0          0   0  \n",
       "\n",
       "[14997 rows x 2500 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We have now converted the data into a x, a 2D array , and y, the categories\n",
    "# The features used are top 2500 'most common words'\n",
    "# Let us visualize our 2D Array\n",
    "df_xtrain = pd.DataFrame(x_train, columns = cols)\n",
    "df_xtrain\n",
    "# Most of the data is zero,since this dataframe is made from a sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement Multinomial Naive Bayes from SKLearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score\t 0.8954457558178303 \n",
      "Test Score\t 0.855\n"
     ]
    }
   ],
   "source": [
    "# Using the inbuild Multinomial Naive Bayes classifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred_sklearn = clf.predict(x_test)\n",
    "train_score = clf.score(x_train, y_train)\n",
    "test_score = clf.score(x_test, y_test)\n",
    "print(\"Train Score\\t\", train_score, \"\\nTest Score\\t\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Multinomial Naive Bayes from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(x_train, y_train):\n",
    "    # Dictionary that we will use to calculate the probabilities while predicting\n",
    "    result = {}\n",
    "    result['total_data'] = y_train.shape[0]\n",
    "    for current_class in set(y_train):\n",
    "        # Since we need to go over unique values only, we use a set\n",
    "        result[current_class] = {}\n",
    "        \n",
    "        # Lets get the part of array which is useful\n",
    "        x_train_current = x_train[y_train == current_class]\n",
    "        y_train_current = y_train[y_train == current_class]\n",
    "        \n",
    "        # Lets keep a count of total_words, since we need to store that value as well\n",
    "        total_words = 0\n",
    "        for j in range(num_features):\n",
    "            # Now we go over all the features, and keep a sum of the words\n",
    "            result[current_class][j] = x_train_current[:,j].sum()\n",
    "            total_words += result[current_class][j]\n",
    "        # Total_count keeps the track of total words, for an entire category\n",
    "        result[current_class]['total_count'] = total_words\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProb(current_class, x, dictionary):\n",
    "    # We initialize the ans with log probability of p(class = current_class) \n",
    "    ans = np.log(dictionary[current_class]['total_count']) - np.log(dictionary['total_data'])\n",
    "    # We go over all the features\n",
    "    for i in range(num_features):\n",
    "        # We calculate the occurance of current word\n",
    "        current_word = dictionary[current_class][i] + 1\n",
    "        # And the occurance of total words\n",
    "        total_words = dictionary[current_class]['total_count'] + len(x)\n",
    "        # And calculate the log probability of the current word\n",
    "        current_word_prob = np.log(current_word) - np.log(total_words)\n",
    "        # We add the probability of current word, as many times as the word occurs\n",
    "        for j in range(x[i]):\n",
    "            ans += current_word_prob\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictSinglePoint(x, dictionary):\n",
    "    best_class = None\n",
    "    best_prob = None\n",
    "    first = True\n",
    "    all_classes = dictionary.keys()\n",
    "    # We go over all the classes \n",
    "    for current_class in all_classes:\n",
    "        if current_class == 'total_data':\n",
    "            continue\n",
    "        # We then calculate the probability of each class\n",
    "        current_prob = getProb(current_class, x, dictionary)\n",
    "        # We choose the class with the highest probability\n",
    "        if first is True or current_prob > best_prob:\n",
    "            best_prob = current_prob\n",
    "            best_class = current_class\n",
    "        first = False\n",
    "    return best_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test, dictionary):\n",
    "    y_predicted = []\n",
    "    for current_x in x_test:\n",
    "        # We go over all the dataset one by one and predict the output for every single point\n",
    "        y_predicted.append(predictSinglePoint(current_x, dictionary))\n",
    "    return np.array(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model on the given data\n",
    "dictionary = fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting using the model\n",
    "y_pred_self = predict(x_test, dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparision between Sklearn Multinomial Naive Bayes and Implementation from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for sklearn MultinomialNB()                           precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.81      0.76       240\n",
      "           comp.graphics       0.76      0.80      0.78       244\n",
      " comp.os.ms-windows.misc       0.82      0.87      0.84       240\n",
      "comp.sys.ibm.pc.hardware       0.88      0.82      0.85       256\n",
      "   comp.sys.mac.hardware       0.90      0.90      0.90       249\n",
      "          comp.windows.x       0.92      0.84      0.88       233\n",
      "            misc.forsale       0.83      0.85      0.84       259\n",
      "               rec.autos       0.84      0.92      0.88       253\n",
      "         rec.motorcycles       0.89      0.94      0.91       231\n",
      "      rec.sport.baseball       0.94      0.96      0.95       236\n",
      "        rec.sport.hockey       0.95      0.94      0.95       261\n",
      "               sci.crypt       0.96      0.93      0.94       269\n",
      "         sci.electronics       0.83      0.89      0.86       246\n",
      "                 sci.med       0.96      0.89      0.92       284\n",
      "               sci.space       0.89      0.89      0.89       248\n",
      "  soc.religion.christian       0.94      1.00      0.97       281\n",
      "      talk.politics.guns       0.73      0.87      0.79       253\n",
      "   talk.politics.mideast       0.94      0.83      0.88       233\n",
      "      talk.politics.misc       0.72      0.68      0.70       248\n",
      "      talk.religion.misc       0.62      0.44      0.51       236\n",
      "\n",
      "                accuracy                           0.85      5000\n",
      "               macro avg       0.85      0.85      0.85      5000\n",
      "            weighted avg       0.85      0.85      0.85      5000\n",
      "\n",
      "Classification report for self-implemented Naive Bayes                            precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.81      0.76       240\n",
      "           comp.graphics       0.76      0.80      0.78       244\n",
      " comp.os.ms-windows.misc       0.82      0.87      0.84       240\n",
      "comp.sys.ibm.pc.hardware       0.88      0.83      0.85       256\n",
      "   comp.sys.mac.hardware       0.91      0.90      0.90       249\n",
      "          comp.windows.x       0.92      0.85      0.88       233\n",
      "            misc.forsale       0.85      0.85      0.85       259\n",
      "               rec.autos       0.84      0.92      0.88       253\n",
      "         rec.motorcycles       0.90      0.94      0.92       231\n",
      "      rec.sport.baseball       0.94      0.96      0.95       236\n",
      "        rec.sport.hockey       0.95      0.94      0.95       261\n",
      "               sci.crypt       0.95      0.93      0.94       269\n",
      "         sci.electronics       0.83      0.88      0.86       246\n",
      "                 sci.med       0.96      0.89      0.93       284\n",
      "               sci.space       0.89      0.89      0.89       248\n",
      "  soc.religion.christian       0.94      1.00      0.97       281\n",
      "      talk.politics.guns       0.73      0.87      0.79       253\n",
      "   talk.politics.mideast       0.94      0.84      0.88       233\n",
      "      talk.politics.misc       0.72      0.68      0.70       248\n",
      "      talk.religion.misc       0.62      0.44      0.51       236\n",
      "\n",
      "                accuracy                           0.86      5000\n",
      "               macro avg       0.85      0.85      0.85      5000\n",
      "            weighted avg       0.86      0.86      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification report for sklearn MultinomialNB()\",classification_report(y_test, y_pred_sklearn))\n",
    "print(\"Classification report for self-implemented Naive Bayes \",classification_report(y_test, y_pred_self))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
